{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization using Regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yall are I take it mostly math/ee/cs types from good schools, and so to good and innocent to interpret this', 'Im a hardened sinner with a BA in  Wiki__Liberal_arts__iablf  from a fairly ok school, and at the risk of scandal, Im here to explain it', '1', 'Mr', 'Edmundson might have 5 students in the 50 who care deeply about Friday', 'Maybe 10; more would require the admissions office at  Wiki__University_of_Virginia__sqaoi  to have mastered time travel', 'He has almost as many whove transferred in at the last minute because of schedule conflicts, and a broad middle bunch in to fulfill a requirement and get a grade', 'For about 80% of the class, then, Mr', 'Edmundson is the keeper of one of about 40 gates they must pass through to get that degree', '2', 'Lets imagine two students, Jim Bored and Jane Engaged', 'Jim cares not for Freud, but he needs the credits toward his degree, which in turn he needs because he wishes to go to law school', 'Indifferent though he is to Freud, he does the reading, does the writing, at semesters end can give a lucid account of Thanatos, Eros, Oedipus, and the psychopathology of everyday life', 'Jane, heaven help her, wants to go to  Wiki__Graduate_school__efbbza  in the  Wiki__Humanities__seiez , and someone has suggested the class to her', 'She does the reading, and quickly comes to agree with  Wiki__Karl_Kraus__folole  that psychoanalysis is a disease masquerading as a cure', 'She bags the class, and spends the time it would have taken in reading Kraus, on to Von Hoffmanstal, Musil, etc., etc., really engaged intellectually', 'Mr', 'Edmundson will I suppose have no option but to give her an F, unless  Wiki__University_of_Virginia__sqaoi  has provision for long-term Incompletes', 'So now Jim will get his B.A., and Jane perhaps not', 'Whatever they know about Freud, kids who get into  Wiki__University_of_Virginia__sqaoi  understand the degree/no-degree distinction in their bones', 'Sorry about that, Mr', 'Edmundson.']\n"
     ]
    }
   ],
   "source": [
    "#tokenize sentences\n",
    "import re\n",
    "text = \"\"\"Yall are I take it mostly math/ee/cs types from good schools, and so to good and innocent to interpret this. Im a hardened sinner with a BA in  Wiki__Liberal_arts__iablf  from a fairly ok school, and at the risk of scandal, Im here to explain it. 1. Mr. Edmundson might have 5 students in the 50 who care deeply about Friday. Maybe 10; more would require the admissions office at  Wiki__University_of_Virginia__sqaoi  to have mastered time travel. He has almost as many whove transferred in at the last minute because of schedule conflicts, and a broad middle bunch in to fulfill a requirement and get a grade. For about 80% of the class, then, Mr. Edmundson is the keeper of one of about 40 gates they must pass through to get that degree. 2. Lets imagine two students, Jim Bored and Jane Engaged. Jim cares not for Freud, but he needs the credits toward his degree, which in turn he needs because he wishes to go to law school. Indifferent though he is to Freud, he does the reading, does the writing, at semesters end can give a lucid account of Thanatos, Eros, Oedipus, and the psychopathology of everyday life. Jane, heaven help her, wants to go to  Wiki__Graduate_school__efbbza  in the  Wiki__Humanities__seiez , and someone has suggested the class to her. She does the reading, and quickly comes to agree with  Wiki__Karl_Kraus__folole  that psychoanalysis is a disease masquerading as a cure. She bags the class, and spends the time it would have taken in reading Kraus, on to Von Hoffmanstal, Musil, etc., etc., really engaged intellectually. Mr. Edmundson will I suppose have no option but to give her an F, unless  Wiki__University_of_Virginia__sqaoi  has provision for long-term Incompletes. So now Jim will get his B.A., and Jane perhaps not. Whatever they know about Freud, kids who get into  Wiki__University_of_Virginia__sqaoi  understand the degree/no-degree distinction in their bones. Sorry about that, Mr. Edmundson.\"\"\"\n",
    "sentences = re.compile('[.!?] ').split(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize using nltk library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yall are I take it mostly math/ee/cs types from good schools, and so to good and innocent to interpret this.',\n",
       " 'Im a hardened sinner with a BA in  Wiki__Liberal_arts__iablf  from a fairly ok school, and at the risk of scandal, Im here to explain it.',\n",
       " '1.',\n",
       " 'Mr. Edmundson might have 5 students in the 50 who care deeply about Friday.',\n",
       " 'Maybe 10; more would require the admissions office at  Wiki__University_of_Virginia__sqaoi  to have mastered time travel.',\n",
       " 'He has almost as many whove transferred in at the last minute because of schedule conflicts, and a broad middle bunch in to fulfill a requirement and get a grade.',\n",
       " 'For about 80% of the class, then, Mr. Edmundson is the keeper of one of about 40 gates they must pass through to get that degree.',\n",
       " '2.',\n",
       " 'Lets imagine two students, Jim Bored and Jane Engaged.',\n",
       " 'Jim cares not for Freud, but he needs the credits toward his degree, which in turn he needs because he wishes to go to law school.',\n",
       " 'Indifferent though he is to Freud, he does the reading, does the writing, at semesters end can give a lucid account of Thanatos, Eros, Oedipus, and the psychopathology of everyday life.',\n",
       " 'Jane, heaven help her, wants to go to  Wiki__Graduate_school__efbbza  in the  Wiki__Humanities__seiez , and someone has suggested the class to her.',\n",
       " 'She does the reading, and quickly comes to agree with  Wiki__Karl_Kraus__folole  that psychoanalysis is a disease masquerading as a cure.',\n",
       " 'She bags the class, and spends the time it would have taken in reading Kraus, on to Von Hoffmanstal, Musil, etc., etc., really engaged intellectually.',\n",
       " 'Mr. Edmundson will I suppose have no option but to give her an F, unless  Wiki__University_of_Virginia__sqaoi  has provision for long-term Incompletes.',\n",
       " 'So now Jim will get his B.A., and Jane perhaps not.',\n",
       " 'Whatever they know about Freud, kids who get into  Wiki__University_of_Virginia__sqaoi  understand the degree/no-degree distinction in their bones.',\n",
       " 'Sorry about that, Mr. Edmundson.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize sentences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "text = \"\"\"Yall are I take it mostly math/ee/cs types from good schools, and so to good and innocent to interpret this. Im a hardened sinner with a BA in  Wiki__Liberal_arts__iablf  from a fairly ok school, and at the risk of scandal, Im here to explain it. 1. Mr. Edmundson might have 5 students in the 50 who care deeply about Friday. Maybe 10; more would require the admissions office at  Wiki__University_of_Virginia__sqaoi  to have mastered time travel. He has almost as many whove transferred in at the last minute because of schedule conflicts, and a broad middle bunch in to fulfill a requirement and get a grade. For about 80% of the class, then, Mr. Edmundson is the keeper of one of about 40 gates they must pass through to get that degree. 2. Lets imagine two students, Jim Bored and Jane Engaged. Jim cares not for Freud, but he needs the credits toward his degree, which in turn he needs because he wishes to go to law school. Indifferent though he is to Freud, he does the reading, does the writing, at semesters end can give a lucid account of Thanatos, Eros, Oedipus, and the psychopathology of everyday life. Jane, heaven help her, wants to go to  Wiki__Graduate_school__efbbza  in the  Wiki__Humanities__seiez , and someone has suggested the class to her. She does the reading, and quickly comes to agree with  Wiki__Karl_Kraus__folole  that psychoanalysis is a disease masquerading as a cure. She bags the class, and spends the time it would have taken in reading Kraus, on to Von Hoffmanstal, Musil, etc., etc., really engaged intellectually. Mr. Edmundson will I suppose have no option but to give her an F, unless  Wiki__University_of_Virginia__sqaoi  has provision for long-term Incompletes. So now Jim will get his B.A., and Jane perhaps not. Whatever they know about Freud, kids who get into  Wiki__University_of_Virginia__sqaoi  understand the degree/no-degree distinction in their bones. Sorry about that, Mr. Edmundson.\"\"\"\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yall are I take it mostly math/ee/cs types from good schools, and so to good and innocent to interpret this.',\n",
       " 'Im a hardened sinner with a BA in  Wiki__Liberal_arts__iablf  from a fairly ok school, and at the risk of scandal, Im here to explain it.',\n",
       " '1.',\n",
       " 'Mr. Edmundson might have 5 students in the 50 who care deeply about Friday.',\n",
       " 'Maybe 10; more would require the admissions office at  Wiki__University_of_Virginia__sqaoi  to have mastered time travel.',\n",
       " 'He has almost as many whove transferred in at the last minute because of schedule conflicts, and a broad middle bunch in to fulfill a requirement and get a grade.',\n",
       " 'For about 80% of the class, then, Mr. Edmundson is the keeper of one of about 40 gates they must pass through to get that degree.',\n",
       " '2.',\n",
       " 'Lets imagine two students, Jim Bored and Jane Engaged.',\n",
       " 'Jim cares not for Freud, but he needs the credits toward his degree, which in turn he needs because he wishes to go to law school.',\n",
       " 'Indifferent though he is to Freud, he does the reading, does the writing, at semesters end can give a lucid account of Thanatos, Eros, Oedipus, and the psychopathology of everyday life.',\n",
       " 'Jane, heaven help her, wants to go to  Wiki__Graduate_school__efbbza  in the  Wiki__Humanities__seiez , and someone has suggested the class to her.',\n",
       " 'She does the reading, and quickly comes to agree with  Wiki__Karl_Kraus__folole  that psychoanalysis is a disease masquerading as a cure.',\n",
       " 'She bags the class, and spends the time it would have taken in reading Kraus, on to Von Hoffmanstal, Musil, etc.,',\n",
       " 'etc.,',\n",
       " 'really engaged intellectually.',\n",
       " 'Mr. Edmundson will I suppose have no option but to give her an F, unless  Wiki__University_of_Virginia__sqaoi  has provision for long-term Incompletes.',\n",
       " 'So now Jim will get his B.A., and Jane perhaps not.',\n",
       " 'Whatever they know about Freud, kids who get into  Wiki__University_of_Virginia__sqaoi  understand the degree/no-degree distinction in their bones.',\n",
       " 'Sorry about that, Mr. Edmundson.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentence tokenizer\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = English()\n",
    "\n",
    "# Create the pipeline 'sentencizer' component\n",
    "sbd = nlp.create_pipe('sentencizer')\n",
    "\n",
    "# Add the component to the pipeline\n",
    "nlp.add_pipe(sbd)\n",
    "\n",
    "text = \"\"\"Yall are I take it mostly math/ee/cs types from good schools, and so to good and innocent to interpret this. Im a hardened sinner with a BA in  Wiki__Liberal_arts__iablf  from a fairly ok school, and at the risk of scandal, Im here to explain it. 1. Mr. Edmundson might have 5 students in the 50 who care deeply about Friday. Maybe 10; more would require the admissions office at  Wiki__University_of_Virginia__sqaoi  to have mastered time travel. He has almost as many whove transferred in at the last minute because of schedule conflicts, and a broad middle bunch in to fulfill a requirement and get a grade. For about 80% of the class, then, Mr. Edmundson is the keeper of one of about 40 gates they must pass through to get that degree. 2. Lets imagine two students, Jim Bored and Jane Engaged. Jim cares not for Freud, but he needs the credits toward his degree, which in turn he needs because he wishes to go to law school. Indifferent though he is to Freud, he does the reading, does the writing, at semesters end can give a lucid account of Thanatos, Eros, Oedipus, and the psychopathology of everyday life. Jane, heaven help her, wants to go to  Wiki__Graduate_school__efbbza  in the  Wiki__Humanities__seiez , and someone has suggested the class to her. She does the reading, and quickly comes to agree with  Wiki__Karl_Kraus__folole  that psychoanalysis is a disease masquerading as a cure. She bags the class, and spends the time it would have taken in reading Kraus, on to Von Hoffmanstal, Musil, etc., etc., really engaged intellectually. Mr. Edmundson will I suppose have no option but to give her an F, unless  Wiki__University_of_Virginia__sqaoi  has provision for long-term Incompletes. So now Jim will get his B.A., and Jane perhaps not. Whatever they know about Freud, kids who get into  Wiki__University_of_Virginia__sqaoi  understand the degree/no-degree distinction in their bones. Sorry about that, Mr. Edmundson.\"\"\"\n",
    "\n",
    "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "doc = nlp(text)\n",
    "\n",
    "# create list of sentence tokens\n",
    "sents_list = []\n",
    "for sent in doc.sents:\n",
    "    sents_list.append(sent.text)\n",
    "sents_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ssund\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ssund\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import statements\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yall are I take it mostly math/ee/cs types fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A few criticisms: [1] Its misrepresentation to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As an embittered victim of exactly this proces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I dont know if this is related to it, but a re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Yall are I take it mostly math/ee/cs types fro...\n",
       "1  A few criticisms: [1] Its misrepresentation to...\n",
       "2  As an embittered victim of exactly this proces...\n",
       "3  I dont know if this is related to it, but a re..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize sentences in dataframe\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "df = pd.read_csv('C:/Users/ssund/PycharmProjects/adm_project1/sample/reddit.csv',encoding = 'utf-8', header=None)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-deda788a63fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"wiki_\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mnew\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mcsv_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                 \u001b[1;31m#wikiword=wikiword+i+\"\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mcsv_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwikiword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas.io.common import EmptyDataError\n",
    "\n",
    "os.chdir('C:/Users/ssund/PycharmProjects/adm_project1/sample/out')\n",
    "from pathlib import Path\n",
    "\n",
    "#filecount=1\n",
    "wiki1=\"C:/Users/ssund/PycharmProjects/adm_project1/sample/out/wiki_word_dataset.txt\"\n",
    "\n",
    "f1= open(wiki1,\"a+\")\n",
    "with open('test.csv','w', newline='\\n', encoding='utf-8') as out_file:\n",
    "    csv_out = csv.writer(out_file)\n",
    "    \n",
    "for fileName in Path('.').glob('*.txt'):\n",
    "    lines = \"\"\n",
    "    wikiword=\"\"\n",
    "    with open(str(fileName.absolute()),'r') as one_text:\n",
    "        lines=one_text.read()\n",
    "        splitwords=lines.split(\"\\n\")\n",
    "        for i in splitwords:\n",
    "            if \"wiki_\" in i.lower():\n",
    "                new=i.split()\n",
    "                csv_out.writerow(new)\n",
    "                #wikiword=wikiword+i+\"\\n\"\n",
    "    csv_out.writerow(wikiword)\n",
    "    #f1.write(wikiword)\n",
    "\n",
    "f1.close()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas.io.common import EmptyDataError\n",
    "\n",
    "os.chdir('C:/Users/ssund/PycharmProjects/adm_project1/reddit')\n",
    "from pathlib import Path\n",
    "\n",
    "wiki1=\"C:/Users/ssund/PycharmProjects/adm_project1/reddit/out/sample.txt\"\n",
    "f1= open(wiki1,\"w+\")\n",
    "for fileName in Path('.').glob('*.txt'):  \n",
    "    lines = \"\"\n",
    "    wikiword = \"\"\n",
    "    with open(str(fileName.absolute()),'r',encoding=\"utf8\") as one_text:\n",
    "        lines=one_text.read()\n",
    "        splitwords=lines.split(\" \")    \n",
    "        for i in splitwords:\n",
    "            if (i.lower()).startswith(\"wiki_\"):       \n",
    "                wikiword=wikiword+i+\"\\n\"\n",
    "        f1.write(wikiword)\n",
    "f1.close()\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing wikifier\n",
    "\n",
    "os.chdir(\"C:/Users/ssund/PycharmProjects/adm_project1/sample/out\")\n",
    "f1=open(\"wiki_word_dataset.txt\",'r')\n",
    "f2=open(\"test.txt\",'w')\n",
    "for w in f1:\n",
    "    f2.write(w.split(\"__\")[1].replace(\"_\",\"\\n\").lower()+'\\n')\n",
    "f1.close()\n",
    "f2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
